{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9705971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import datetime\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "from pyspark.sql.functions import sum,max,min,mean,count\n",
    "import datetime as dt\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import findspark\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "from os.path import abspath\n",
    "\n",
    "warehouse_location = abspath('spark-warehouse')\n",
    "with open('cfg.yml') as f:\n",
    "    config = yaml.load(f, Loader = SafeLoader)\n",
    "\n",
    "findspark.init()\n",
    "spark = SparkSession.builder \\\n",
    "    .master(config['spark']['spark_master'])\\\n",
    "    .appName('gather')\\\n",
    "    .enableHiveSupport()\\\n",
    "    .config('spark.sql.warehouse.dir', warehouse_location)\\\n",
    "    .config(config['spark']['spark_jars'], config['spark']['spark_jars_path'])\\\n",
    "    .config('spark.cores.max', '2')\\\n",
    "    .config('spark.executor.cores', '2')\\\n",
    "    .getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "spark\n",
    "\n",
    "url = config['postgres']['url']\n",
    "properties = {\n",
    "    'user': config['postgres']['user'],\n",
    "    'password' : config['postgres']['user'],\n",
    "    'url': url,\n",
    "    'driver': config['postgres']['driver']\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1998854",
   "metadata": {},
   "source": [
    "# Training the Model on a Single Stock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c295390",
   "metadata": {},
   "source": [
    "## Retrieve data from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228f7615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_data(ticker_list, from_date, to_date):\n",
    "    sentiment = spark.read.jbdc(url = url, 'sentiment', properties = properties).dropDuplicates()\n",
    "    finance = spark.read.jbdc(url = url, 'company_data', properties = properties).dropDuplicates()\n",
    "    condition = [finance.date == sentiment.date, finance.ticker == sentiment.ticker]\n",
    "    full_data = finance.join(sentiment, condition).fillna(0)\n",
    "    full_data.createOrReplaceTempView('dataset')\n",
    "    df_list = []\n",
    "    for ticker in ticker_list:\n",
    "        try:\n",
    "            working_data = spark.sql(\"Select * from dataset where ticker == \" + str(ticker) + \" & date between \"+str(from_date) + \" and \"+ str(to_date))\n",
    "        except:\n",
    "            print(\"Failed to Retrieve Data from Database for ticker \" + str(ticker) + \". Please load necessary data and retry query\")\n",
    "        df_list.append(working_data.toPandas().sort_values(by = 'date', ascending = True))\n",
    "    return df_list\n",
    "dfs = return_data(['MSFT', 'GOOG'], \"2018-01-01\", \"2023-02-02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f6c41a",
   "metadata": {},
   "source": [
    "## Scale Numeric Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e14583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "target_scaler = MinMaxScaler()\n",
    "def scale(df_list):\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    target_scaler = MinMaxScaler()\n",
    "    for df in df_list:\n",
    "        data = df.drop(['ticker'],axis=1)\n",
    "    # features and target columns\n",
    "        target = target_scaler.fit_transform(data['target'])\n",
    "        X_feat = data.drop(['target'], axis = 1)\n",
    "        for col in X_feat.columns:\n",
    "            X_feat[col] = scaler.fit_transform(X_feat[col])\n",
    "    return X_feat, target_scaler, target\n",
    "X_feat, target_scaler = scale(dfs)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69929a5",
   "metadata": {},
   "source": [
    "## Format Training Data for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cede73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a data structure with 10 time-steps and 1 output\n",
    " \n",
    "# Split data into X_train and y_train data sets\n",
    "def lstm_split(data,target,steps):\n",
    "      X = []\n",
    "      y = []\n",
    "      # Creating a data structure with 10 time-steps and 1 output\n",
    "      for i in range(10, steps):\n",
    "          X.append(data[i-10:i])\n",
    "          y.append(target[i:i+1])  \n",
    "      return np.array(X),np.array(y)\n",
    " \n",
    "X1,y1 = lstm_split(X_feat,target,len(X_feat))\n",
    " \n",
    "train_split = 0.9\n",
    "split_idx = int(np.ceil(len(X1)*train_split))\n",
    "date_index = X_feat.index\n",
    " \n",
    "X_train,X_test = X1[:split_idx],X1[split_idx:]\n",
    "y_train,y_test = y1[:split_idx],y1[split_idx:]\n",
    "X_train_date,X_test_date = date_index[:split_idx],date_index[split_idx:]\n",
    " \n",
    "print(X1.shape,X_train.shape,X_test.shape,y_test.shape,y_train.shape)\n",
    "print(X_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74ee092",
   "metadata": {},
   "source": [
    "## Constructing the Primary LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1291ac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM Framework\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.metrics import Precision\n",
    "from keras.optimizers import Adam\n",
    "#!pip install keras_tuner\n",
    "import keras_tuner\n",
    "\n",
    "#define function to create model, optional hyperparameters included to be selected during training\n",
    "LR = 0.05\n",
    "def build_model(hp):\n",
    "  model = Sequential()\n",
    "  hidden = hp.Choice('n_hidden', [0,1,2,3])\n",
    "  model.add(LSTM(units = hp.Int('neurons_visible', min_value = X_train.shape[2], max_value = 100, step = 20),\n",
    "                activation = hp.Choice('activate1', ['sigmoid', 'relu']),\n",
    "                input_shape = (X_train.shape[1], X_train.shape[2]),\n",
    "                return_sequences = True if hidden >0 else False))\n",
    "  #Configure hidden layers based on random search determined hidden layer number\n",
    "  if hidden > 0:\n",
    "    for num in range(hidden):\n",
    "      model.add(Dropout(hp.Float('dropout' +str(num+1), min_value = 0.1, max_value = 0.9, step = 0.3)))\n",
    "      model.add(LSTM(units = hp.Int('neurons_hidden'+str(num+1), min_value = 20, max_value = 50, step = 10),\n",
    "                     activation = 'relu', return_sequences = True if num != hidden else False))\n",
    "      \n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "  #compile the model\n",
    "  model.compile(loss = 'mean_squared_error', optimizer = Adam(lr = LR), metrics = ['mean_squared_error'])\n",
    "  \n",
    "  return model\n",
    "\n",
    "#set learning rate and early stopping callbacks\n",
    "LR_decay = ReduceLROnPlateau('loss', patience=1, verbose=0, \n",
    "                             factor=0.5, min_lr=1e-8)\n",
    "Early_stop = EarlyStopping(monitor='loss', min_delta=0, \n",
    "                           patience=25, verbose=1, mode='auto',\n",
    "                           baseline=0, restore_best_weights=True)\n",
    "#arrange random search class\n",
    "tune = keras_tuner.RandomSearch(build_model, objective = 'val_loss', max_trials = 50, seed = 1)\n",
    "\n",
    "#complete training \n",
    "tune.search(X_train, y_train, epochs = 200, batch_size = 24, validation_data = (X_test, y_test), callbacks = [LR_decay, Early_stop])\n",
    "\n",
    "LSTM_model = tune.get_best_models()[0]\n",
    "LSTM_model.save('LSTM_model.h5')\n",
    "hyperparameters = tune.get_best_hyperparameters(1)[0]\n",
    "print(hyperparameters.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f3b4e0",
   "metadata": {},
   "source": [
    "## Constructing the Prophet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8d6357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c86314",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSFT_Data = finance_data[finance_data['ticker']=='MSFT']\n",
    "# This function is used to get the train data and test data\n",
    "def data_preparation(df):\n",
    "  data=df[[\"date\",\"adj_close\"]]\n",
    "  data = data.rename(columns = {'date':'ds', 'adj_close':'y'})\n",
    "  return data\n",
    "# Define parameter grid to search over\n",
    "param_grid = {\n",
    "    'seasonality_mode': ['additive', 'multiplicative'],\n",
    "    'changepoint_prior_scale': [0.01, 0.1, 1.0],\n",
    "    'seasonality_prior_scale': [0.01, 0.1, 1.0],\n",
    "}\n",
    "\n",
    "# Initialize minimum error and best parameters\n",
    "min_error = float('inf')\n",
    "best_params = {}\n",
    "\n",
    "# Loop through all parameter combinations\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print('Testing parameters:', params)\n",
    "\n",
    "    # Initialize Prophet model with specified hyperparameters\n",
    "    model = Prophet(**params)\n",
    "    model.fit(data_preparation(MSFT_Data))\n",
    "\n",
    "    # Perform time series cross-validation\n",
    "    df_cv = cross_validation(model=model, initial='1000 days', horizon='10 days', period='10 days')\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    df_metrics = performance_metrics(df_cv)\n",
    "\n",
    "    # Calculate mean cross-validation error\n",
    "    mean_cv_error = df_metrics['mse'].mean()\n",
    "\n",
    "    # Update minimum error and best parameters if new minimum is found\n",
    "    if mean_cv_error < min_error:\n",
    "        min_error = mean_cv_error\n",
    "        best_params = params\n",
    "\n",
    "# Print best hyperparameters and corresponding error\n",
    "print('Best parameters:', best_params)\n",
    "print('Minimum cross-validation error:', min_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc10496e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the best parameter to fit the model\n",
    "final_model = Prophet(**best_params)\n",
    "final_model.fit(data_preparation(MSFT_Data))\n",
    "\n",
    "future = final_model.make_future_dataframe(periods=100)\n",
    "validation_predict = final_model.predict(future)\n",
    "print(validation_predict[['ds', 'yhat', 'yhat_lower', 'yhat_upper']])\n",
    "fig = final_model.plot(validation_predict)\n",
    "fig1 = final_model.plot_components(validation_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9924e7",
   "metadata": {},
   "source": [
    "## Format Predictions of Sub-Models to Create Final Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37684228",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = load('LSTM_model.h5')\n",
    "preds_dict = {}\n",
    "\n",
    "preds_dict['lstm_pred'] = lstm.predict(X_train)\n",
    "preds_dict['prophet_pred_microsoft'] = f\n",
    "\n",
    "hybrid_train = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1cf90c",
   "metadata": {},
   "source": [
    "## Constructing the Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2444ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.01\n",
    "#General LSTM model based on randomsearch results\n",
    "def multiple_models(x_train, y_train):\n",
    "    hybrid = Sequential()\n",
    "    hybrid.add(LSTM(units = 8, activation = \"relu\", input_shape = (X_train.shape[1], X_train.shape[2]), return_sequences = True))\n",
    "    hybrid.add(Dropout(0.5))\n",
    "    hybrid.add(LSTM(units = 12, activation = 'relu', return_sequences = True))\n",
    "    hybrid.add(Dropout(0.5))\n",
    "    hybrid.add(LSTM(units = 12))\n",
    "    hybrid.add(Dropout(0.5))\n",
    "    hybrid.add(Dense(units =1)\n",
    "    hybrid.compile(loss = 'mean_squared_error', optimizer = Adam(lr = LR), metrics = [\"mean_squared_error\"])\n",
    "    Early_stop = EarlyStopping(monitor='val_loss', min_delta=0, \n",
    "                              patience=25, verbose=1, mode='auto',\n",
    "                              baseline=0, restore_best_weights=True)\n",
    "    hybrid.fit(x_train, y_train, epochs = 200, batch_size = 24, callbacks = [Early_stop])\n",
    "    return hybrid\n",
    "#train the hybrid model\n",
    "hybrid1 = multiple_models(hybrid_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff6b8b1",
   "metadata": {},
   "source": [
    "# Model Testing Single Company Hybrid Model vs. LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287210ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep google test data\n",
    "google = frames[0]\n",
    "google_target_scaler = MinMaxScaler()\n",
    "google_target = google_target_scaler.fit_transform(google[['target']])\n",
    "google_score = google['score']\n",
    "test_ft = google.drop(['target', 'score', 'ticker'], axis = 1)\n",
    "\n",
    "# Normalise the data\n",
    "\n",
    "for col in test_ft.columns:\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    X_feat[col] = scaler.fit_transform(test_ft[[col]])\n",
    "test_ft['score'] = google_score\n",
    "test_ft = np.array(test_ft)\n",
    "google_ft, google_target = lstm_split(test_ft,google_target,len(google_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bd26f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.evaluate_model()\n",
    "hybrid1.evaluate_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d157e6",
   "metadata": {},
   "source": [
    "# Expanded Model: Multiple Companies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c55dfd",
   "metadata": {},
   "source": [
    "## Retrieve Data from DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1257a920",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = return_data(['MSFT', 'GOOG', 'AMZN', \"NFLX\", \"TSLA\"], \"2018-01-01\", \"2023-02-02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce64bd97",
   "metadata": {},
   "source": [
    "## Create Sub-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f259fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lists(list_of_df):\n",
    "  training_list = []\n",
    "  target_list = []\n",
    "  for i in list_of_df:\n",
    "    data = frames[i]\n",
    "    score = data['score']\n",
    "    target = data['target']\n",
    "    training = data.drop(['target', 'ticker', 'score'], axis = 1)\n",
    "    scaler = MinMaxScaler()\n",
    "    for col in training.columns:\n",
    "      training[col] = scaler.fit_transform(training[col])\n",
    "    training['score'] = score\n",
    "    data_x, data_y = lstm_split(training, target, 10)\n",
    "    training_list.append(data_x)\n",
    "    target_list.append(data_y)\n",
    "  return training_list, target_list\n",
    "\n",
    "#Train each of the lstm models on training companies\n",
    "training_list, target_list = create_lists(frames)\n",
    "for tick, x_train, y_train in zip(ticker_list, training_list, target_list):\n",
    "  model = multiple_models(tick, x_train, y_train)\n",
    "  model.save('/models/'+tick+'_lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484e75ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Train Data for Hybrid Model Using Microsoft Predictions\n",
    "def hybrid_train(direct, ticker_list, hybrid_train):\n",
    "    preds_dict = {}\n",
    "    path = direct\n",
    "    for num, model in enumerate(os.listdir(path)):\n",
    "        model = load_model(model)\n",
    "        prediction = model.predict(hybrid_train)\n",
    "        preds_dict[ticker_list[num]] = prediction\n",
    "    preds_df = pd.DatFrame(preds_dict)\n",
    "    return preds_df\n",
    "\n",
    "ticker_list = [\"MSFT\", \"NFLX\", \"AMZN\", \"TSLA\"]\n",
    "hybrid_training_data =  hybrid_train(\"/models/\", ticker_list, X_train) \n",
    "hybrid_training_data['prophet'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5cda19",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_expanded = multiple_models(hybrid_training_data, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c166d9",
   "metadata": {},
   "source": [
    "## Test Hybrid Model Using Microsoft Validation Data and Google Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e1f51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "google_test = {}\n",
    "microsoft_test = {}\n",
    "path = '/models/'\n",
    "for num, model in enumerate(os.listdir(path)):\n",
    "  model = load_model(model)\n",
    "  goog_preds = model.predict(google_ft)\n",
    "  micro_preds = model.predict(X_test)\n",
    "  google_test[ticker_list[num]] = goog_preds\n",
    "  microsoft_test[ticker_list[num]] = micro_preds\n",
    "google_test = pd.DataFrame(google_test)\n",
    "microsoft_test = pd.DataFrame(microsoft_test)\n",
    "google_test['prophet'] = \n",
    "microsoft_test['prophet'] = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aabe931",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8920ae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
